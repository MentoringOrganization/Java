# 💡 (4주차) 자바 예상 질문 정리

# 📜 복습

## ArrayList가 capacity를 넘어서게 되면 어떤 일이 발생하는가?
ArrayList는 내부적으로 Object[] 배열을 가지고 있다. 만약 capacity를 넘어서 element를 추가하려 하면 기존 배열의 크기를 1.5배로 확장해 새로운 배열을 만들어 내고 기존 배열에서 새로운 배열로 내용을 복사하게 된다. 시간복잡도는 기존 배열의 크기를 N이라 하면 O(N)이다.

## ArrayList의 add()메서드의 bigO가 어떻게 되는가?
ArrayList의 add는 O(1)의 시간복잡도를 가진다. 이는 해당 인덱스에 값을 추가하기만 하면 되기 때문이다. 반면, 만약 capacity를 넘어서는 경우 새로운 배열을 생성하고 기존의 배열의 요소를 복사해야하기 때문에 시간 복잡도가 O(N)이 된다.
또한 만약 add(index,element)를 통해 중간에 요소를 추가한다면 O(N)이 된다.

## ArrayList의 remove()메서드의 bigO를 설명하고 이를 LinkedList와 비교하여라.
특정 인덱스의 요소를 삭제하는 경우 뒤의 요소를 한단계씩 채워 넣는 작업이 필요하기 때문에 O(N)의 시간복잡도를 가진다.
매개변수로 넘어온 특정 요소를 삭제하는 경우 특정 요소를 찾아내는데 O(N)의 탐색시간이 들고 삭제후 한 단계씩 채워 넣는 작업도 O(N)이므로 최종 시간복잡도도 O(N)이다.

### removeAll의 시간복잡도는 어떻게 되는가? (최적화가 들어가는거 같은데 아직 이해못함)
단순 O(N^2)은 아닌거 같다. 최적화를 위해 잘 설계된거 같기는 하나 아직 이해 못했다.

## ArrayList의 get()메서드의 bigO를 설명하고 이를 LinkedLIst와 비교하여라.
인덱스를 통해 바로 접근이 가능하므로 O(1)이다 반면 LinkedLIst는 처음부터 순서대로 노드를 탐색해야 하므로 O(N)이다.

## 그냥 Object[]를 사용하면 안되는건가? 왜 굳이 ArrayList를 사용하는거지?
일반 배열과는 다르게 ArrayList는 Generic을 확인할 수 있다. Long배열을 Object[] 배열 참조변수가 가리키고 있다고 하자. Object[] 참조변수에 String을 대입한다면 Runtime에 에러가 발생한다. 반면 ArrayList는 Generic을 활용할 수 있으며 이는 Compile Time에 에러를 확인 할 수 있게 한다. 

## HashMap의 내부 구현방식에 대해 설명하라.
HashMap은 HashTable처럼 동작한다. Node<K,V>[] table을 가지고 있고 각 인덱스에는 기본적으로는 링크드 리스트로 구현되어있다. 어떤 값이 HashMap에 삽입될 경우 해당 객체의 Key값으로 hashFuntion을 거치고 인덱스가 된다. 만약 충돌이 발생할 경우 링크드 리스트 혹은 binary Search tree형태로 버켓에 여러 노드가 삽입될 수 있다.

## HashMap hash(key) => key.hashcode() ^ h >>> 16로 구현되어있다. 왜 이렇게 구현했을까?
HashMap의 Hash Function은 [hash(key) & (capacity-1)]인데 이는 capacity가 2^n이라 할 때 key 해시값의 하위 n-1비트를 인덱스로 하겠다는 의미이다. 하지만 만약에 key의 hash값이 왼쪽 비트는 값이 다르나 오른쪽 비트는 값이 같은 경우가 많다면, 해당 Hash Function은 균등하게 hash값을 분포시키지 못한다. 즉, 충돌이 너무 자주 일어날 수 있다. 위 코드는 h >>> 16은 hashCode의 상위 16비트만 남겨 오른쪽으로 bit shift연산을 한것이고 이것을 다시 hashCode와 XOR연산을 한다. 이는 상위 비트와 하위비트를 XOR연산하여 하위 16비트를 썪어주는 역할을 한다.(hashCode는 int형으로 4Byte 즉 32bit 자료형이다.) 따라서 index값으로 해시코드의 하위 코드만 사용하는 경우가 많은 Hash Function의 약점을 보완해주는 역할을 한다. 왜 하필 XOR연산이냐 라고 한다면 두가지 이유가 있다.
1. XOR연산은 AND나 OR보다 빠르다.
2. AND는 1이 나올 확률이 1/4로 bit 1과 bit 0이 1:3의 비율로 결과가 나타난다. OR은 1이 나올 확률이 3/4으로 3:1의 비율로 결과가 나온다.
   반면 XOR은 둘중 하나만 1이여야 결과로 1을 반환하므로 bit 1과 0이 1:1의 비율로 나타나 이상적이다.따라서 AND 나 OR연산을 사용하는 것 보다,
   Hash Function을 통해 나온 해시값이 균등하게 분포할 수 있다.

## HashMap의 LoadFactor에 대해 설명하라.
HashMap은 capacity의 LoadFactor비율만큼 채워지면 HashMap은 리사이징된다. capacity * LoadFactor => threshold라고 한다.
HashMap의 element 개수가 threshold를 넘어가면 HashMap이 리사이징 되어 기존보다 2배 큰 table이 생성된다.

### LoadFactor가 높아지면 뭐가 안좋은가?
LoadFactor가 높아지면 그만큼 충돌이 일어난 인덱스가 많을 것이다. 따라서 get()을 통해 요소를 찾을 때, 같은 bucket에 여러개의 요소가 있어 값을 찾는 탐색시간이 길어질 수 있다. 따라서 일정 이하의 LoadFactor를 유지해 주어야 높은 성능을 보장할 수 있다.

## treefiy_threshold를 설명하라.
Bucket에 연관된 Node의 개수가 많아지면 이는 HashMap의 검색 속도에 치명적인 영향을 끼친다. HashMap의 검색 속도는 Bucket이 링크드 리스트로 구현되어있다고 할 때, O(n)의 BigO를 가진다. 따라서 Bucket에 연관된 Node의 개수가 많아지면 검색 속도가 너무 느려지게 되는데 이 때는 Bucket을 링크드 리스트 구조로 구현하지 않고 Binary Search Tree형태로 변경한다. 하나의 버켓에 연관된 Node가 일정 개수를 넘어설 때, Bucket을 tree구조로 바꿔야 하는데 이때 기준이 treefiy_threshold이다. 즉, 버켓에 연관된 Node의 개수가 treefiy_threshold를 넘어서게 되면 Bucket의 구조를 Binary Search Tree로 변경한다. 만약 버켓의 구조가 untreeify_threshold보다 다시 줄어들면 Tree구조에서 다시 링크드리스트 구조로 변경된다. 굳이 untreeify_threshold가 따로 존재하는 이유는 버킷의 개수를 n이라 할 때, n=treefiy_threshold -> treefiy_threshold-1 -> treefiy_threshold 처럼 크기가 경계선에서 반복되면 Bucket의 구조를 계속해서 바꿔야 하므로 overHead가 너무 심해진다. 따라서 untreeify_threshold를 따로 주어 저런 경우를 최대한 피하려 했다.

### Node의 구조가 TreeNode구조가 되는일은 잘 없다. 그 이유를 설명하라.
HashMap에 저장된 element의 개수가 많아지면 LoadFactor의 값이 증가하게 되고 곧 hashTable가 2배로 증가하고 기존 Node들이 여러 Bucket으로 흩어진다. 따라서 하나의 Bucket에 많은 Node가 할당되어 있다는 것은 key의 hashCode()가 잘 못 오버라이딩 되었다는 것을 의미한다. 잘 못 오버라이딩 되었다의 의미는 hashCode가 균등하게 분포되지 못했다는 것을 의미한다. 따라서 잘 구현한 hashCode()메서드를 가진 key라면 Node의 구조가 TreeNode구조로 변경될 일은 거의 없다.

## HashMap의 put()메서드를 호출했을 때 내부적으로 동작하는 방식을 설명하고 시간 복잡도를 설명하라.
HashMap은 HashFunction을 거쳐서 HashTable의 어느 indext에 Entry가 저장될지 결정된다. 만약 충돌이 발생하지 않았다면 바로 저장될 수 있으므로 O(1)이다.
만약 충돌이 발생하였고 해당 Bucket이 LinkedList로 구현되어 있다면, 해당 Bucket에 연관된 Entry를 하나씩 순회하여 저장될 공간을 찾아야 하므로 O(N)의 시간복잡도를 갖는다. (N : 해당 Bucket에 연관된 Entry의 수)
해당 Bucket이 이진 탐색 트리로 구현되어 있다면, 저장될 공간을 찾기위해 O(log2 N)만큼의 탐색이 필요하기 때문에 삽입또한 O(log2 N)의 시간복잡도를 갖는다. (N: 해당 Bucket에 연관된 Entry의 수)
만약 삽입하는 순간 treefiy_threshold를 넘어서 해당 Bucket이 tree구조로 변경되어야 한다면 O(N * log2 N)의 시간복잡도를 가지며 최악의 경우이다.
이때는 해당 Bucket의 모든 Entry가 이진 검색 트리에 삽입되어야 한다. 이진 검색 트리에 삽입 연산은 일반적으로 O(log n)이며 n개를 삽입해야 하므로 O(N * log N)을 띄게된다.


### 해당 element가 hashTable의 어느 인덱스에 저장될지를 어떻게 결정하는가?
HashFunction의 outPut이 hashTable의 인덱스가 된다. HashFunction은 H(key)=key.hashCode() & key.hashCode() >>> 16 이다. 
이런식으로 구현된 이유는 앞선 질문을 참고하길 바란다.

## HashMap의 resize()메서드가 동작하는 방식을 설명하고 시간 복잡도를 설명하라.
HashMap에 저장된 Node의 전체 개수를 N이라 할 때, HashMap이 resize될 때, 각 Entry가 모두 새로운 hashTable로 복사되어야 하므로 O(N)이라 할 수 있다.

## HashMap의 get()메서드를 호출했을 때 내부적으로 동작하는 방식을 설명하고 시간 복잡도를 설명하라.
HashMap의 get(Object key)메서드를 호출하면 HashFunction을 통해 index를 얻는다. hashTable[index]를 통해 해당 index에 값이 저장되어 있는지 확인한다.해당 bucket에서 Entry를 가져와 hashCode를 먼저 비교한다. hashCode가 같다면 동등성을 비교한다. 만약에 hashCode와 동등성 비교를 모두 통과한다면 동일한 Entry로 취급하고 반환한다. 만약 같지 않다면, 다음 노드를 확인한다. 해당 버킷의 모든 노드를 탐색하여도 일치하는 노드가 없다면 찾고자 하는 Object가 없다는 뜻이다.

시간복잡도는 일반적으로 O(1)의 결과를 가지나 conflict가 일어나 chaining된 상태라면 최악의 경우 O(N)이 나타날 수도 있다. 또한 해당 Bucket에 너무 많은 노드가 연결되어 있어 해당 Bucket이 Tree구조를 띄는 경우 O(log N)의 시간 복잡도를 가진다.

## HashMap의 remove()메서드를 호출 했을 때 내부적으로 동작하는 방식을 설명하고 시간 복잡도를 설명하라.
일반적으로 O(1)의 시간복잡도를 가지지만, conflict이 일어나 해당 버킷에 chaining되어있는 경우 O(N)의 시간복잡도가 나타난다.
만약 해당 버킷이 red-black tree구조로 되어있는 경우 삭제하는데 O(log N)의 시간복잡도가 소요된다. ( 회전이라는 연산이 상수시간에 수행될 수 있어서 그렇다는데 아직 이해 못했다.)
만약 tree구조를 다시 linkedList구조로 바꿔야 한다면, 시간 복잡도는 O(N)이 된다.

# 📚 예습
## 서버와 클라이언트가 각각 무엇인지 설명하여라.

## IP주소가 있을 때, Subnet mask를 통해 Network주소와 Host주소를 얻어내는 방법을 설명하여라.

## TCP와 UDP를 비교하라.

### UDP가 TCP보다 빠를 수 있는 이유를 설명하라.

### UDP가 사용되는 예시, TCP가 사용되는 예시를 하나씩 설명하라.

## Fork/Join에 대해 설명하라.

### 위 기능을 사용하는 이유가 무엇인가?

### work stealing에 대해 설명하라.

