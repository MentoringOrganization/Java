# 💡 (4주차) 자바 예상 질문 정리

# 📜 복습

## ArrayList가 capacity를 넘어서게 되면 어떤 일이 발생하는가?
ArrayList는 내부적으로 Object[] 배열을 가지고 있다. 만약 capacity를 넘어서 element를 추가하려 하면 기존 배열의 크기를 1.5배로 확장해 새로운 배열을 만들어 내고 기존 배열에서 새로운 배열로 내용을 복사하게 된다. 시간복잡도는 기존 배열의 크기를 N이라 하면 O(N)이다.

## ArrayList의 add()메서드의 bigO가 어떻게 되는가?
ArrayList의 add는 O(1)의 시간복잡도를 가진다. 이는 해당 인덱스에 값을 추가하기만 하면 되기 때문이다. 반면, 만약 capacity를 넘어서는 경우 새로운 배열을 생성하고 기존의 배열의 요소를 복사해야하기 때문에 시간 복잡도가 O(N)이 된다.
또한 만약 add(index,element)를 통해 중간에 요소를 추가한다면 O(N)이 된다.

## ArrayList의 remove()메서드의 bigO를 설명하고 이를 LinkedList와 비교하여라.
특정 인덱스의 요소를 삭제하는 경우 뒤의 요소를 한단계씩 채워 넣는 작업이 필요하기 때문에 O(N)의 시간복잡도를 가진다.
매개변수로 넘어온 특정 요소를 삭제하는 경우 특정 요소를 찾아내는데 O(N)의 탐색시간이 들고 삭제후 한 단계씩 채워 넣는 작업도 O(N)이므로 최종 시간복잡도도 O(N)이다.

### removeAll의 시간복잡도는 어떻게 되는가? (최적화가 들어가는거 같은데 아직 이해못함)
단순 O(N^2)은 아닌거 같다. 최적화를 위해 잘 설계된거 같기는 하나 아직 이해 못했다.

## ArrayList의 get()메서드의 bigO를 설명하고 이를 LinkedLIst와 비교하여라.
인덱스를 통해 바로 접근이 가능하므로 O(1)이다 반면 LinkedLIst는 처음부터 순서대로 노드를 탐색해야 하므로 O(N)이다.

## 그냥 Object[]를 사용하면 안되는건가? 왜 굳이 ArrayList를 사용하는거지?
일반 배열과는 다르게 ArrayList는 Generic을 확인할 수 있다. Long배열을 Object[] 배열 참조변수가 가리키고 있다고 하자. Object[] 참조변수에 String을 대입한다면 Runtime에 에러가 발생한다. 반면 ArrayList는 Generic을 활용할 수 있으며 이는 Compile Time에 에러를 확인 할 수 있게 한다. 

## HashMap의 내부 구현방식에 대해 설명하라.
HashMap은 HashTable처럼 동작한다. Node<K,V>[] table을 가지고 있고 각 인덱스에는 기본적으로는 링크드 리스트로 구현되어있다. 어떤 값이 HashMap에 삽입될 경우 해당 객체의 Key값으로 hashFuntion을 거치고 인덱스가 된다. 만약 충돌이 발생할 경우 링크드 리스트 혹은 binary Search tree형태로 버켓에 여러 노드가 삽입될 수 있다.

## HashMap hash(key) => key.hashcode() ^ h >>> 16로 구현되어있다. 왜 이렇게 구현했을까?
HashMap의 Hash Function은 [hash(key) & (capacity-1)]인데 이는 capacity가 2^n이라 할 때 key 해시값의 하위 n-1비트를 인덱스로 하겠다는 의미이다. 하지만 만약에 key의 hash값이 왼쪽 비트는 값이 다르나 오른쪽 비트는 값이 같은 경우가 많다면, 해당 Hash Function은 균등하게 hash값을 분포시키지 못한다. 즉, 충돌이 너무 자주 일어날 수 있다. 위 코드는 h >>> 16은 hashCode의 상위 16비트만 남겨 오른쪽으로 bit shift연산을 한것이고 이것을 다시 hashCode와 XOR연산을 한다. 이는 상위 비트와 하위비트를 XOR연산하여 하위 16비트를 썪어주는 역할을 한다.(hashCode는 int형으로 4Byte 즉 32bit 자료형이다.) 따라서 index값으로 해시코드의 하위 코드만 사용하는 경우가 많은 Hash Function의 약점을 보완해주는 역할을 한다. 왜 하필 XOR연산이냐 라고 한다면 두가지 이유가 있다.
1. XOR연산은 AND나 OR보다 빠르다.
2. AND는 1이 나올 확률이 1/4로 bit 1과 bit 0이 1:3의 비율로 결과가 나타난다. OR은 1이 나올 확률이 3/4으로 3:1의 비율로 결과가 나온다.
   반면 XOR은 둘중 하나만 1이여야 결과로 1을 반환하므로 bit 1과 0이 1:1의 비율로 나타나 이상적이다.따라서 AND 나 OR연산을 사용하는 것 보다,
   Hash Function을 통해 나온 해시값이 균등하게 분포할 수 있다.

## HashMap의 LoadFactor에 대해 설명하라.
HashMap은 capacity의 LoadFactor비율만큼 채워지면 HashMap은 리사이징된다. capacity * LoadFactor => threshold라고 한다.
HashMap의 element 개수가 threshold를 넘어가면 HashMap이 리사이징 되어 기존보다 2배 큰 table이 생성된다.

### LoadFactor가 높아지면 뭐가 안좋은가?
LoadFactor가 높아지면 그만큼 충돌이 일어난 인덱스가 많을 것이다. 따라서 get()을 통해 요소를 찾을 때, 같은 bucket에 여러개의 요소가 있어 값을 찾는 탐색시간이 길어질 수 있다. 따라서 일정 이하의 LoadFactor를 유지해 주어야 높은 성능을 보장할 수 있다.

## treefiy_threshold를 설명하라.
Bucket에 연관된 Node의 개수가 많아지면 이는 HashMap의 검색 속도에 치명적인 영향을 끼친다. HashMap의 검색 속도는 Bucket이 링크드 리스트로 구현되어있다고 할 때, O(n)의 BigO를 가진다. 따라서 Bucket에 연관된 Node의 개수가 많아지면 검색 속도가 너무 느려지게 되는데 이 때는 Bucket을 링크드 리스트 구조로 구현하지 않고 Binary Search Tree형태로 변경한다. 하나의 버켓에 연관된 Node가 일정 개수를 넘어설 때, Bucket을 tree구조로 바꿔야 하는데 이때 기준이 treefiy_threshold이다. 즉, 버켓에 연관된 Node의 개수가 treefiy_threshold를 넘어서게 되면 Bucket의 구조를 Binary Search Tree로 변경한다. 만약 버켓의 구조가 untreeify_threshold보다 다시 줄어들면 Tree구조에서 다시 링크드리스트 구조로 변경된다. 굳이 untreeify_threshold가 따로 존재하는 이유는 버킷의 개수를 n이라 할 때, n=treefiy_threshold -> treefiy_threshold-1 -> treefiy_threshold 처럼 크기가 경계선에서 반복되면 Bucket의 구조를 계속해서 바꿔야 하므로 overHead가 너무 심해진다. 따라서 untreeify_threshold를 따로 주어 저런 경우를 최대한 피하려 했다.

### Node의 구조가 TreeNode구조가 되는일은 잘 없다. 그 이유를 설명하라.
HashMap에 저장된 element의 개수가 많아지면 LoadFactor의 값이 증가하게 되고 곧 hashTable가 2배로 증가하고 기존 Node들이 여러 Bucket으로 흩어진다. 따라서 하나의 Bucket에 많은 Node가 할당되어 있다는 것은 key의 hashCode()가 잘 못 오버라이딩 되었다는 것을 의미한다. 잘 못 오버라이딩 되었다의 의미는 hashCode가 균등하게 분포되지 못했다는 것을 의미한다. 따라서 잘 구현한 hashCode()메서드를 가진 key라면 Node의 구조가 TreeNode구조로 변경될 일은 거의 없다.

## HashMap의 put()메서드를 호출했을 때 내부적으로 동작하는 방식을 설명하고 시간 복잡도를 설명하라.
HashMap은 HashFunction을 거쳐서 HashTable의 어느 indext에 Entry가 저장될지 결정된다. 만약 충돌이 발생하지 않았다면 바로 저장될 수 있으므로 O(1)이다.
만약 충돌이 발생하였고 해당 Bucket이 LinkedList로 구현되어 있다면, 해당 Bucket에 연관된 Entry를 하나씩 순회하여 저장될 공간을 찾아야 하므로 O(N)의 시간복잡도를 갖는다. (N : 해당 Bucket에 연관된 Entry의 수)
해당 Bucket이 이진 탐색 트리로 구현되어 있다면, 저장될 공간을 찾기위해 O(log2 N)만큼의 탐색이 필요하기 때문에 삽입또한 O(log2 N)의 시간복잡도를 갖는다. (N: 해당 Bucket에 연관된 Entry의 수)
만약 삽입하는 순간 treefiy_threshold를 넘어서 해당 Bucket이 tree구조로 변경되어야 한다면 O(N * log2 N)의 시간복잡도를 가지며 최악의 경우이다.
이때는 해당 Bucket의 모든 Entry가 이진 검색 트리에 삽입되어야 한다. 이진 검색 트리에 삽입 연산은 일반적으로 O(log n)이며 n개를 삽입해야 하므로 O(N * log N)을 띄게된다.


### 해당 element가 hashTable의 어느 인덱스에 저장될지를 어떻게 결정하는가?
HashFunction의 outPut이 hashTable의 인덱스가 된다. HashFunction은 H(key)=key.hashCode() & key.hashCode() >>> 16 이다. 
이런식으로 구현된 이유는 앞선 질문을 참고하길 바란다.

## HashMap의 resize()메서드가 동작하는 방식을 설명하고 시간 복잡도를 설명하라.
HashMap에 저장된 Node의 전체 개수를 N이라 할 때, HashMap이 resize될 때, 각 Entry가 모두 새로운 hashTable로 복사되어야 하므로 O(N)이라 할 수 있다.

## HashMap의 get()메서드를 호출했을 때 내부적으로 동작하는 방식을 설명하고 시간 복잡도를 설명하라.
HashMap의 get(Object key)메서드를 호출하면 HashFunction을 통해 index를 얻는다. hashTable[index]를 통해 해당 index에 값이 저장되어 있는지 확인한다.해당 bucket에서 Entry를 가져와 hashCode를 먼저 비교한다. hashCode가 같다면 동등성을 비교한다. 만약에 hashCode와 동등성 비교를 모두 통과한다면 동일한 Entry로 취급하고 반환한다. 만약 같지 않다면, 다음 노드를 확인한다. 해당 버킷의 모든 노드를 탐색하여도 일치하는 노드가 없다면 찾고자 하는 Object가 없다는 뜻이다.

시간복잡도는 일반적으로 O(1)의 결과를 가지나 conflict가 일어나 chaining된 상태라면 최악의 경우 O(N)이 나타날 수도 있다. 또한 해당 Bucket에 너무 많은 노드가 연결되어 있어 해당 Bucket이 Tree구조를 띄는 경우 O(log N)의 시간 복잡도를 가진다.

## HashMap의 remove()메서드를 호출 했을 때 내부적으로 동작하는 방식을 설명하고 시간 복잡도를 설명하라.
일반적으로 O(1)의 시간복잡도를 가지지만, conflict이 일어나 해당 버킷에 chaining되어있는 경우 O(N)의 시간복잡도가 나타난다.
만약 해당 버킷이 red-black tree구조로 되어있는 경우 삭제하는데 O(log N)의 시간복잡도가 소요된다. ( 회전이라는 연산이 상수시간에 수행될 수 있어서 그렇다는데 아직 이해 못했다.)
만약 tree구조를 다시 linkedList구조로 바꿔야 한다면, 시간 복잡도는 O(N)이 된다.

# 📚 예습
## 서버와 클라이언트가 각각 무엇인지 설명하여라.
서버-클라이언트 개념을 이해하기 위해서는 식당을 생각하면 좋다. 우리가 식당에가면 서빙하는 직원 분들이 계신다. 우리는 이 직원들을 서빙하는 사람 즉, 서버(serve + -er)라고 부른다. 실제 서버 언어의 기원이라고 하는데 맞는지는 모르겠다. 다만 해당 비유가 서버 - 클라이언트 개념을 이해하는데 두움이 되므로 해당 글에서는 이를 따르겠다.
우리가 식당에 들어가면 서버분에게 많은 것을 요구할 수 있다. 메뉴를 주문할 수도 있고, 물, 물티슈, 수저를 요구할 수도 있다. 테이블을 닦아 달라고 말하기도 한다. 서버는 받은 요청들을 가지고 내가 할 수 있는 것인지, 아니면 주방의 도움이 필요한지 판단한다. 주문 받은 메뉴를 주방에 전달하고 요리가 완료되면 요리를 다시 클라이언트(손님)에게 가져다 준다. 요리를 하려면 재료들을 냉장고에서 꺼내야하는데 이를 DB라고 비유할 수 있다.
물, 물티슈, 수저와 같이 서버가 직접 대응해줄 수 있는 것은 바로 대응해주기도 한다.
이렇듯 여러 종류의 요청을 받고 그에 맞는 응답을 내려주는 것을 서버라고 부른다. 반대로 서버에게 요청을 하는 주체를 클라이언트라고 부른다.
서버는 항상 서버인 것은 아니다. 손님에게 메뉴를 주문받은 서버는 주방에 주문표를 전달하고 추후 요리를 전달받는다. 이때 서버는 클라이언트의 역할, 주방이 서버의 역할이 된다. 서버 - 클라이언트 개념은 상대적인 것으로 클라이언트가 서버가 될 수도 서버가 클라이언트가 될 수도 있으며, 클라이언트가 요청한 요구사항을 위해 몇개의 서버를 거치기도 한다.

## IP주소가 있을 때, Subnet mask를 통해 Network주소와 Host주소를 얻어내는 방법을 설명하여라.
IP주소는 Network주소와 Host주소로 분리된다. IP주소의 종류에 따라 주소 길이의 비율이 다르다.
IP주소 체계는 총 32비트로 구성되며 xxxxxxxx.xxxxxxxx.xxxxxxxx.xxxxxxx 와 같이 3개의 온점으로 4개의 영역으로 구분된다.
IP주소의 체계에 따라 CLASS A에서는 앞 8비트, Class B에서는 앞 16비트,Class C에서는 앞 24비트가 Network주소를 나타낸다.
IP주소의 어디까지가 Network인지를 나타내기 위해 subnet mask를 사용한다.IP주소 & Subnet mask 연산을 통해 나타난 결과 값이 Network주소가 되는 방식이다. Class A에서는 subnetMask가 11111111.00000000.00000000.00000000이므로 &연산을 진행하면 network주소만 남는 식이다.

## TCP와 UDP를 비교하라.
데이터 전송 속도면에서 TCP가 UDP보다 속도가 느리다.
TCP는 데이터 손실이 일어날 가능성이 없으나 UDP는 데이터 손실이 일어날 수도 있다.
TCP는 전송한 순서가 도착순서인 반면, UDP는 전송 순서와 도착 순서가 무관하다.

### UDP가 TCP보다 빠를 수 있는 이유를 설명하고 TCP가 UDP보다 신뢰성이 높다고 말하는 이유를 설명하라.
TCP는 패킷을 전송할 때, SEQ, ACK를 주고받는다. 만약 Server가 Client에게 SEQ 1000 패킷을 전달했고 데이터 크기가 100 Byte였다면 Client는 Server에게 1101 ACK를 전달한다. 이를 통해 패킷을 잘 전달받았으며 패킷의 데이터 크기인 100 Byte를 옳게 전달 받았음을 확인할 수 있다. ACK를 받은 Server는 다음 패킷을 전달한다. 만약 ACK가 돌아오지 않거나 1101 ACK가 아닌 1051 ACK와 같이 데이터 크기가 맞지 않으면 패킷의 전체 혹은 일부가 손실되었다고 판단하고 Server는 패킷을 재전송한다. 이를 통해 TCP는 데이터 손실이 일어나지 않음을 보장한다. 반면 UDP는 이러한 과정을 거치지 않으므로 데이터 손실이 일어날 수 있다. 또한 위와 같은 방식으로 순서대로 하나씩 패킷을 보내기 때문에 전송한 순서가 곧 도착순서인 반면에, UDP는 전송 속도와 도착 순서가 다를 수 있다. TCP는 패킷을 보낼때 마다 응답을 받고 다음 패킷을 보내기 때문에 전송 속도가 UDP보다 느리다.

### UDP가 사용되는 예시, TCP가 사용되는 예시를 하나씩 설명하라.
TCP는 웹 브라우저 사용에 적합하다. Spring Boot 서버에 요청이 들어올 때, 데이터가 손실되어서 들어온다면 서버는 정상적인 응답을 내려줄 수 없을 것이다. 따라서 여기서는 데이터의 신뢰성이 중요하므로 TCP가 적합하다. 반면에 Youtube 실시간 방송을 보는 경우는 UDP가 적합하다. 데이터의 손실이 있어 픽셀 몇개가 잠시 동안 깨지더라도 영상을 보는데 큰 영향은 없다. 반면 데이터 전송 속도가 느리면 계속 버퍼링이 걸리므로 영상을 보기가 힘들다.
따라서 데이터의 전송속도가 중요한 Youtube에서는 UDP가 적합하다.

## Fork/Join에 대해 설명하라.
Fork/Join기능은 thread를 개발자가 쉽게 다룰 수 있도록 도와주는 기능이다. compute기능을 재귀적으로 작성하여 사용할 수 있다.

### 위 기능을 사용하는 이유가 무엇인가?
Fork/Join기능을 이용하면 개발자가 별도로 구현하지 않아도 work Stealing이 제공된다는 장점이 있다. work Stealing이란 여러 쓰레드는 각각이 수행할 작업 을 Deque에 저장하게 되는데 어느 하나의 쓰레드에는 부하가 많이 부담되고 있고 다른 쓰레드에는 부하가 적을 때, 부하가 많은 쓰레드의 Deque에 있는 업무를 부하가 없는 쓰레드의 Deque로 넘겨주는 기능을 말한다.

